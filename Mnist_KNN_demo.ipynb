{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76dffc-e7ad-450b-bcb4-a1a26260f8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b05d8c9-a8bd-4184-b47e-2cdfa32f1922",
   "metadata": {},
   "outputs": [],
   "source": [
    "+---------+------------------+-----------------+\n",
    "| Class   |   Training Count |   Testing Count |\n",
    "+=========+==================+=================+\n",
    "| Class 0 |             5923 |             980 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 1 |             6742 |            1135 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 2 |             5958 |            1032 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 3 |             6131 |            1010 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 4 |             5842 |             982 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 5 |             5421 |             892 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 6 |             5918 |             958 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 7 |             6265 |            1028 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 8 |             5851 |             974 |\n",
    "+---------+------------------+-----------------+\n",
    "| Class 9 |             5949 |            1009 |\n",
    "+---------+------------------+-----------------+\n",
    "Total Count\n",
    "Training\t59,000\n",
    "Testing\t    10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174fd699-6d57-44a3-9319-1cef97ebf4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "#https://www.geeksforgeeks.org/differences-and-applications-of-list-tuple-set-and-dictionary-in-python/ \n",
    "#https://medium.com/@jodancker/a-brief-introduction-to-distance-measures-ac89cbd2298 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33b4b54-16fe-4766-88b8-990a1f0800fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_images_from_folder(folder_path):\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in sorted(os.listdir(folder_path)):\n",
    "        class_path = os.path.join(folder_path, label)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_file in tqdm(os.listdir(class_path), desc=f\"Loading {label}\"):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (28, 28))\n",
    "                images.append(img.flatten())\n",
    "                labels.append(int(label))\n",
    "    return np.array(images), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbb8d29b-4bf0-4dc0-b984-d1b38c3425ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_knn_model(mnist_dir, k=3):\n",
    "    train_dir = os.path.join(mnist_dir, \"Training\")\n",
    "    test_dir = os.path.join(mnist_dir, \"Testing\")\n",
    "\n",
    "    print(\"Loading training data...\")\n",
    "    X_train, y_train = load_mnist_images_from_folder(train_dir)\n",
    "\n",
    "    print(\"Loading test data...\")\n",
    "    X_test, y_test = load_mnist_images_from_folder(test_dir)\n",
    "\n",
    "    print(f\"\\n=== Training KNN | K = {k} ===\")\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    joblib.dump(knn, \"knn_mnist_model.pkl\")\n",
    "    print(\"\\n Model saved as 'knn_mnist_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d643f0e-a49a-40a8-a552-c75e8716cf2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 0: 100%|██████████████████████████████████████████████████████████████████████████████| 5923/5923 [00:01<00:00, 3552.39it/s]\n",
      "Loading 1: 100%|██████████████████████████████████████████████████████████████████████████████| 6742/6742 [00:01<00:00, 3679.97it/s]\n",
      "Loading 2: 100%|██████████████████████████████████████████████████████████████████████████████| 5958/5958 [00:01<00:00, 4618.57it/s]\n",
      "Loading 3: 100%|██████████████████████████████████████████████████████████████████████████████| 6131/6131 [00:01<00:00, 4579.97it/s]\n",
      "Loading 4: 100%|██████████████████████████████████████████████████████████████████████████████| 5842/5842 [00:01<00:00, 4213.69it/s]\n",
      "Loading 5: 100%|██████████████████████████████████████████████████████████████████████████████| 5421/5421 [00:01<00:00, 3925.39it/s]\n",
      "Loading 6: 100%|██████████████████████████████████████████████████████████████████████████████| 5918/5918 [00:01<00:00, 4747.68it/s]\n",
      "Loading 7: 100%|██████████████████████████████████████████████████████████████████████████████| 6265/6265 [00:01<00:00, 4599.09it/s]\n",
      "Loading 8: 100%|██████████████████████████████████████████████████████████████████████████████| 5851/5851 [00:01<00:00, 4554.32it/s]\n",
      "Loading 9: 100%|██████████████████████████████████████████████████████████████████████████████| 5949/5949 [00:01<00:00, 3921.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading 0: 100%|████████████████████████████████████████████████████████████████████████████████| 980/980 [00:00<00:00, 4461.67it/s]\n",
      "Loading 1: 100%|██████████████████████████████████████████████████████████████████████████████| 1135/1135 [00:00<00:00, 4295.99it/s]\n",
      "Loading 2: 100%|██████████████████████████████████████████████████████████████████████████████| 1032/1032 [00:00<00:00, 4482.24it/s]\n",
      "Loading 3: 100%|██████████████████████████████████████████████████████████████████████████████| 1010/1010 [00:00<00:00, 4204.64it/s]\n",
      "Loading 4: 100%|████████████████████████████████████████████████████████████████████████████████| 982/982 [00:00<00:00, 4606.70it/s]\n",
      "Loading 5: 100%|████████████████████████████████████████████████████████████████████████████████| 892/892 [00:00<00:00, 4740.34it/s]\n",
      "Loading 6: 100%|████████████████████████████████████████████████████████████████████████████████| 958/958 [00:00<00:00, 4395.67it/s]\n",
      "Loading 7: 100%|██████████████████████████████████████████████████████████████████████████████| 1028/1028 [00:00<00:00, 4521.12it/s]\n",
      "Loading 8: 100%|████████████████████████████████████████████████████████████████████████████████| 974/974 [00:00<00:00, 4423.56it/s]\n",
      "Loading 9: 100%|██████████████████████████████████████████████████████████████████████████████| 1009/1009 [00:00<00:00, 4355.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training KNN | K = 3 ===\n",
      "Accuracy: 0.9698\n",
      "Confusion Matrix:\n",
      " [[ 973    1    1    0    0    1    3    1    0    0]\n",
      " [   0 1132    2    0    0    0    1    0    0    0]\n",
      " [  10    9  997    2    0    0    0   13    1    0]\n",
      " [   0    2    4  975    1   14    1    7    3    3]\n",
      " [   1    5    0    0  952    0    4    2    0   18]\n",
      " [   6    1    0   13    2  859    5    1    1    4]\n",
      " [   5    3    0    0    3    3  944    0    0    0]\n",
      " [   0   23    5    0    1    0    0  989    0   10]\n",
      " [   9    2    4   17    8   13    3    5  909    4]\n",
      " [   3    5    2    7    9    3    1    9    2  968]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       980\n",
      "           1       0.96      1.00      0.98      1135\n",
      "           2       0.98      0.97      0.97      1032\n",
      "           3       0.96      0.97      0.96      1010\n",
      "           4       0.98      0.97      0.97       982\n",
      "           5       0.96      0.96      0.96       892\n",
      "           6       0.98      0.99      0.98       958\n",
      "           7       0.96      0.96      0.96      1028\n",
      "           8       0.99      0.93      0.96       974\n",
      "           9       0.96      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n",
      "\n",
      " Model saved as 'knn_mnist_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Set your dataset path\n",
    "MNIST_DIR = \"D:\\\\JupyterNotebooks\\\\KNN\\\\MNIST\"  \n",
    "train_knn_model(MNIST_DIR, k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab68d6c5-dbc3-4f25-90f0-b50401863f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_user_image(model_path, image_path):\n",
    "    \"\"\"\n",
    "    Predict digit from user image using saved KNN model.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Model file '{model_path}' not found.\")\n",
    "        return\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file '{image_path}' not found.\")\n",
    "        return\n",
    "\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    img_flattened = img.flatten().reshape(1, -1)\n",
    "\n",
    "    prediction = model.predict(img_flattened)[0]\n",
    "    print(f\"Prediction for image '{image_path}': {prediction}\")\n",
    "    # Display original image using matplotlib\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted Digit: {prediction}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d994e5fb-5521-4b5a-bca8-d5bd61519ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a new user image\n",
    "user_image_path = \"path/to/user_digit_image.png\"  # ⬅️ Replace with actual image path\n",
    "infer_user_image(\"knn_mnist_model.pkl\", user_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3ebd57-ad74-45b5-b57b-6c51ee273aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path of your digit image:  s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Model file 'knn_mnist_model.pkl' not found.\n"
     ]
    }
   ],
   "source": [
    "# Test with a new user image by taking the file path input from the user\n",
    "user_image_path = input(\"Enter the path of your digit image: \")  # Takes user input for the image path\n",
    "\n",
    "infer_user_image(\"knn_mnist_model.pkl\", user_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f45a705-7b02-4338-9de2-8291c6bf0ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected image: D:/JupyterNotebooks/KNN/MNIST/Training/1/3.jpg\n",
      "Prediction for image 'D:/JupyterNotebooks/KNN/MNIST/Training/1/3.jpg': 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Tkinter root window (it won't be shown)\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "\n",
    "# Open file dialog to select an image\n",
    "user_image_path = filedialog.askopenfilename(title=\"Select your digit image\", filetypes=[(\"PNG files\", \"*.png\"), (\"JPEG files\", \"*.jpg;*.jpeg\"), (\"All files\", \"*.*\")])\n",
    "\n",
    "# If the user selected a file, proceed with inference\n",
    "if user_image_path:\n",
    "    print(f\"Selected image: {user_image_path}\")\n",
    "    infer_user_image(\"knn_mnist_model.pkl\", user_image_path)\n",
    "else:\n",
    "    print(\"No image selected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14386843-6f3d-48e5-b9b0-efe5c828b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_knn.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def load_mnist_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in sorted(os.listdir(folder_path)):\n",
    "        class_path = os.path.join(folder_path, label)\n",
    "        if os.path.isdir(class_path):\n",
    "            for img_file in tqdm(os.listdir(class_path), desc=f\"Loading {label}\"):\n",
    "                img_path = os.path.join(class_path, img_file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (28, 28))  # ensure fixed shape\n",
    "                images.append(img.flatten())     # flatten to 1D\n",
    "                labels.append(int(label))\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def knn_mnist_classification(mnist_dir, k_values=[1, 3, 5]):\n",
    "    train_dir = os.path.join(mnist_dir, \"Training\")\n",
    "    test_dir = os.path.join(mnist_dir, \"Testing\")\n",
    "\n",
    "    print(\"Loading training data...\")\n",
    "    X_train, y_train = load_mnist_images_from_folder(train_dir)\n",
    "\n",
    "    print(\"Loading test data...\")\n",
    "    X_test, y_test = load_mnist_images_from_folder(test_dir)\n",
    "\n",
    "    for k in k_values:\n",
    "        print(f\"\\n=== KNN for MNIST Dataset | K = {k} ===\")\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45b7c49-f2c5-4d00-83ee-6d7904d9b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_mnist_classification(mnist_dir=\"D:\\\\JupyterNotebooks\\\\KNN\\\\MNIST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab4f77-222d-487c-b56f-284215968e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420d71f7-c9ef-4b74-8706-556e0aea6897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3c73e-0d0b-496d-8081-3ab15431edf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce8ebd-19ac-4104-b896-3c963678ef86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
